{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZgGNXZEfywz"
   },
   "source": [
    "#Task 1: Tokenization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "deLPHwbIX3-r"
   },
   "outputs": [],
   "source": [
    "# Download gutenberg dataset\n",
    "# This is the dataset on which all your models will be trained\n",
    "# https://drive.google.com/file/d/0B2Mzhc7popBga2RkcWZNcjlRTGM/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08q0ospof2z9"
   },
   "outputs": [],
   "source": [
    "import sys, re\n",
    "import string\n",
    "import glob\n",
    "import math\n",
    "\n",
    "# ------------------------------------ Tokenize sentence -------------------------------------------------------\n",
    "def replace_char(p,r,text):\n",
    "    t = \"\"\n",
    "    if r == 1:\n",
    "        t =\" \"\n",
    "    if r == 2:\n",
    "        t ==\". \"\n",
    "    for x in p:\n",
    "        text = text.replace(x,t)\n",
    "    return text\n",
    "\n",
    "def replace_digit(text):\n",
    "    for x in text:\n",
    "        if x.isdigit():\n",
    "            text = text.replace(x,\"\")\n",
    "    return text\n",
    "\n",
    "def handling_newlines(text):\n",
    "    text = text.replace(\"\\n\\n\" , \". \")\n",
    "    text = text.replace(\".\\n\\n\" , \". \")\n",
    "    text = text.replace(\"..\" , \".\")\n",
    "    return text\n",
    "\n",
    "def tokenize(text,sent,tok):\n",
    "    # Given text, tokenise into sentences and words. Take into consideration various delimiters.\n",
    "    text = text.lower()\n",
    "    \n",
    "    px = [\"[\",\"]\",\"'s\",\"(\",\")\",\"\\\"\",\"%\",\"$\",\"*\",\"&\",\"^\",\"=\",\"+\",\"`\",\"'\"] \n",
    "    text = replace_char(px,0,text)\n",
    "    text = replace_digit(text)\n",
    "    text = handling_newlines(text)    \n",
    "    p = [\":--\",\"-\",\"\\n\",\"  \",\"_\",\",\",\";\",\":\",\"/\",\"{\",\"}\"]\n",
    "    text = replace_char(p,1,text)\n",
    "    p1 = [\"!\",\"?\"]\n",
    "    text = replace_char(p1,2,text)\n",
    "    \n",
    "    sentences = []\n",
    "    s = \"<SOS> \"\n",
    "    for word in text:\n",
    "        if word.endswith('.'):\n",
    "            word = word[:-1]\n",
    "            s = s + word+\" <EOS>\"\n",
    "         \n",
    "            if s != \"<SOS>  <EOS>\":\n",
    "                s = s.replace(\"  \",\" \")\n",
    "                sentences.append(s.strip())\n",
    "            s = \"<SOS> \"\n",
    "        \n",
    "        else:\n",
    "            s = s + word\n",
    "            \n",
    "    for sent1 in sentences:\n",
    "        if sent1 == \" \" or sent1 == \"\":\n",
    "            remove(sent1)\n",
    "            \n",
    "    sent.extend(sentences)        \n",
    "    tokens = text.split()\n",
    "    lower_tokens = []\n",
    "    for x in tokens:\n",
    "        if x == '' or len(x)==0:\n",
    "            print(\"hi\")\n",
    "            continue\n",
    "        lower_tokens.append(x.lower())\n",
    "    punct = string.punctuation\n",
    "    table = str.maketrans('','',punct)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    tok.extend(stripped)\n",
    "    return tok,sent\n",
    "\n",
    "def get_tokens():\n",
    "    sentences = []\n",
    "    tokens = []\n",
    "    path = '/home/rahil/Desktop/Gutenberg/txt/*.txt'\n",
    "    files = glob.glob(path)\n",
    "    i = 0\n",
    "    for name in files:\n",
    "        file = open(name, 'rt')\n",
    "        text = file.read()\n",
    "        tokens,sentences = tokenize(text,sentences,tokens)\n",
    "        i+=1\n",
    "    return tokens,sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gwBEe5bgAbn"
   },
   "source": [
    "Language Model and Smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------- Build your language model ---------------------------------------------\n",
    "def language_model(tokens,sentences):\n",
    "    global unigramDict\n",
    "    global bigramDict    \n",
    "    trigramLangModel(tokens,sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigramLangModel(words):\n",
    "    global vocabSize   \n",
    "    for word in words:\n",
    "        if len(word) == 0:\n",
    "            continue\n",
    "        if word != startOfSentence and word != endOfSentence:\n",
    "            unigramDict[word] = unigramDict.get(word,0) + 1\n",
    "            vocabSize += 1 \n",
    "        \n",
    "def bigramLangModel(a,sentences):\n",
    "    unigramLangModel(a)\n",
    "    unique_bigrams = set()\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.split()\n",
    "        \n",
    "        previous_word = None\n",
    "        for word in sentence:           \n",
    "            if previous_word != None:\n",
    "                bigramDict[(previous_word,word)] = bigramDict.get((previous_word,word),0) + 1\n",
    "\n",
    "            if previous_word != startOfSentence and previous_word != endOfSentence:\n",
    "                unique_bigrams.add((previous_word,word))\n",
    "            previous_word = word\n",
    "    \n",
    "def trigramLangModel(a,sentences):\n",
    "    bigramLangModel(a,sentences)\n",
    "    unique_trigrams = set()\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.split()\n",
    "        prev1_word = None\n",
    "        prev2_word = None\n",
    "        for word in sentence:\n",
    "            if prev1_word != None and prev2_word != None:\n",
    "                trigramDict[(prev1_word,prev2_word,word)] = trigramDict.get((prev1_word,prev2_word,word),0) + 1\n",
    "\n",
    "                if prev1_word != startOfSentence and prev1_word != endOfSentence:\n",
    "                    unique_trigrams.add((prev1_word,prev2_word,word))\n",
    "            prev1_word = prev2_word\n",
    "            prev2_word = word\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete Ngram function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Th9ogrogKTO"
   },
   "outputs": [],
   "source": [
    "# Given (N-1) gram, and the value 'N', print the possibilities that complete the n-gram\n",
    "# and plot them in decresing order of frequency\n",
    "\n",
    "def cmp(l1,l2):\n",
    "    if len(l1) != len(l2):\n",
    "        return -1\n",
    "    for i in range(0,len(l1)):\n",
    "        if l1[i] != l2[i]:\n",
    "            return -1\n",
    "        \n",
    "    return 0\n",
    "\n",
    "def completeNgram(ngram, n):\n",
    "    temp1 = {}\n",
    "    if n==2:\n",
    "        temp = ngram[-(n-1):]\n",
    "        for k,v in bigramDict.items():\n",
    "                if cmp(k[:-1],temp) == 0:\n",
    "                    temp1[k[-1]] = v\n",
    "        \n",
    "    elif n>=3:\n",
    "        temp = ngram[-2:]\n",
    "        for k,v in trigramDict.items():\n",
    "                if cmp(k[-3:-1],temp) == 0:\n",
    "                    temp1[k] = v\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    temp2 = sorted(temp1.items(),key = itemgetter(1),reverse = True)\n",
    "    print(\"\\n--------------- completeNgram ----------------\\n\")\n",
    "    print(\"When \" + str(ngram) + \" was given\\n\")\n",
    "    \n",
    "    for x in temp2:\n",
    "        print(str(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------- Perform Stupid Backoff smoothing ------------------------------------------\n",
    "def stupidBackOff(word,sentence):\n",
    "    finalResult = 0.0\n",
    "    \n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i]!='<SOS>' and sentence[i]!='<EOS>' and sentence[i-1]!='<SOS>': \n",
    "            bi_key = (sentence[i - 1],sentence[i])\n",
    "            count_bigram = bigramDict.get(bi_key,0)\n",
    "            count_unigram = unigramDict.get(sentence[i - 1],0)\n",
    "            \n",
    "            if count_bigram > 0:\n",
    "                finalResult += math.log(count_bigram)\n",
    "                finalResult -= math.log(count_unigram)\n",
    "            \n",
    "            else:\n",
    "                count_unigram = unigramDict[sentence[i]]\n",
    "                finalResult += math.log(count_unigram + 1)\n",
    "                finalResult -= math.log(vocabSize * 2)\n",
    "                finalResult += math.log(0.4)\n",
    "    \n",
    "    return finalResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------- Perform Laplace smoothing ------------------------------------------\n",
    "def laplaceSmoothing(num,denum,n):\n",
    "    \n",
    "    num += 1    \n",
    "    if n == 2:\n",
    "        denum += len(unigramDict) + 1\n",
    "    elif n == 3:\n",
    "        denum += len(bigramDict) + 1\n",
    "    return num,denum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------- Perform Good Turing smoothing -----------------------------------------\n",
    "def goodTuring(dict1):  \n",
    "    nrs = {}\n",
    "    for k, v in dict1.items():                                 # reverse indexing\n",
    "        if v not in nrs:\n",
    "            nrs[v] = []\n",
    "        nrs[v].append(k)\n",
    "        \n",
    "    nr_counts = {k : len(v) for k, v in nrs.items()}\n",
    "    nr_probs = {k : (k*v)/float(N) for k, v in nr_counts.items()}\n",
    "    sorted_nrs = sorted(nr_counts.items())\n",
    "    sorted_probs = sorted(nr_probs.items())\n",
    "    MAX = sorted_nrs[0][1]\n",
    "            \n",
    "    for r, nr in nrs.items():\n",
    "        if (r+1) in nrs:\n",
    "            #print(nrs[r+1])\n",
    "            new_nr = float((r+1) * len(nrs[r+1])) / float(N) \n",
    "        else:\n",
    "            new_nr = MAX*r**-2 / float(N)\n",
    "        \n",
    "    return new_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- Deleted Interpolation --------------------------------------------\n",
    "import numpy as np\n",
    "def deleted_interpolation(unigram_c,bigram_c,trigram_c):\n",
    "    lambda1 = 0\n",
    "    lambda2 = 0\n",
    "    lambda3 = 0\n",
    "    for a, b, c in trigram_c.keys():\n",
    "        if a != '<SOS>':\n",
    "            v = trigram_c[list(a, b, c)]\n",
    "            if v > 0:\n",
    "                try:\n",
    "                    c1 = float(v-1)/(bigram_c[list(a, b)]-1)\n",
    "                except ZeroDivisionError:\n",
    "                    c1 = 0\n",
    "                try:\n",
    "                    c2 = float(bigram_c[list(a, b)]-1)/(unigram_c[a]-1)\n",
    "                except ZeroDivisionError:\n",
    "                    c2 = 0\n",
    "                try:\n",
    "                    c3 = float(unigram_c[a]-1)/(sum(unigram_c.values())-1)\n",
    "                except ZeroDivisionError:\n",
    "                    c3 = 0            \n",
    "                clist = [c1, c2, c3]\n",
    "                m = np.argmax(clist)\n",
    "                if m == 0:\n",
    "                    lambda3 += v\n",
    "                if m == 1:\n",
    "                    lambda2 += v\n",
    "                if m == 2:\n",
    "                    lambda1 += v\n",
    "\n",
    "    weights = [lambda1, lambda2, lambda3]\n",
    "    weights = [float(a) / sum(weights) for a in weights]\n",
    "    \n",
    "    print(weights)\n",
    "    return weights\n",
    "\n",
    "def cal_probs():\n",
    "    unigram_total = sum(unigramDict.values())\n",
    "\n",
    "    for k in unigramDict.items():\n",
    "        unigram_p[k] = math.log(unigramDict[k], 2) - math.log(vocabSize, 2) if k != \"<SOS>\" and k != '' and len(k)>0 else 0\n",
    "        \n",
    "    for k in bigramDict.items():\n",
    "        bigram_p[k] = math.log(bigramDict[k], 2) - math.log(unigramDict[k[0]], 2) if k[0] != \"<SOS>\" else 0\n",
    "    \n",
    "    for k in trigramDict.items():\n",
    "        trigram_p[k] = math.log(trigramDict[k], 2) - math.log(bigramDict[k[:-1]], 2) if k[0] != \"<SOS>\" else 0\n",
    "    \n",
    "    weights = deleted_interpolation(unigramDict, bigramDict, trigramDict)\n",
    "    trigram_d = math.log(weights[0] * (2**trigram_p) + weights[1] * (2**bigram_p) + weights[2] * (2**unigram_p), 2)\n",
    "    return trigram_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjoF5Wlsaf_M"
   },
   "source": [
    "#Task 2: Unigrams and Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oehobp6dbXp7"
   },
   "outputs": [],
   "source": [
    "# ---------------------------------- Top 10 and Bottom 10 frequencies ----------------------------------\n",
    "def ngramFreqPlot(ngrams):\n",
    "    \n",
    "    temp =  {}\n",
    "    for key,value in ngrams.items():\n",
    "        temp_str = str(key)\n",
    "        temp[temp_str] = value\n",
    "    \n",
    "    # Calculate unigram frequencies and plot them in the descending order of frequency\n",
    "    temp = OrderedDict(sorted(temp.items(),key = itemgetter(1),reverse = True))       \n",
    "    word = list(temp.keys())\n",
    "    freq = list(temp.values())\n",
    "    plot_ngram_freqs(word,freq)\n",
    "    \n",
    "    w = []\n",
    "    \n",
    "    print(\"\\n----------------- Top 10 ---------------\\n\")\n",
    "    w = sorted(temp.items(),key = itemgetter(1),reverse = True)\n",
    "    for i in w[:10]:\n",
    "         print(str(i[0]) + \" --> \" + str(temp[i[0]]))\n",
    "    \n",
    "    print(\"\\n----------------- Bottom 10 ---------------\\n\")\n",
    "    for i in w[len(temp)-10:]:\n",
    "        print(str(i[0]) + \" --> \" + str(temp[i[0]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------- Plot ngrams vs freq plot ----------------------------------------------\n",
    "def plot_ngram_freqs(word,freq):\n",
    "    \n",
    "    # Create and style traces\n",
    "    trace0 = go.Scatter(x = word,y = freq,name = 'Plot Ngrams_freq',line = dict(color = ('rgb(205, 12, 24)'),width = 2))   \n",
    "    data = [trace0]\n",
    "\n",
    "    # Edit the layout\n",
    "    layout = dict(title = 'Plot of ngrams vs frequency',xaxis = dict(title = 'word'),yaxis = dict(title = 'frequency',type='log',autorange=False))\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    py.iplot(fig, filename='styled-line')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- Spelling checker ------------------------------------------\n",
    "# Given a word check if the spelling is correct using your Language model\n",
    "#     probabilistic_spellcorrection(\"across\")\n",
    "\n",
    "def probabilistic_spellcorrection(word):\n",
    "#     print(a)\n",
    "    char_unigram = {}\n",
    "    for cu in word:\n",
    "        for l in cu:\n",
    "            char_unigram[l] = char_unigram.get(l,0) + unigramDict[cu]\n",
    "        \n",
    "    char_bigram = {}\n",
    "    for cb in word:\n",
    "        for index in range(0,len(cb)-1):\n",
    "            char_bigram[(cb[index],cb[index+1])] = char_bigram.get((cb[index],cb[index+1]),0) + freq_dict_unigram[cb]\n",
    "            \n",
    "    print(char_unigram)\n",
    "    print(\"\\n\\n\")\n",
    "    print(char_bigram)\n",
    "\n",
    "def spellCheck(word, n_grams):    \n",
    "    word = word.lower()\n",
    "    return (set(edit_distance(word)) & set(unigramDict.keys()))\n",
    "    \n",
    "def edit_distance(word):\n",
    "    alphabet = set('abcdefghijklmnopqrstuvwxyz')\n",
    "    \n",
    "    splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes    = [a + b[1:] for a, b in splits if b]\n",
    "    transposes = [a + b[1] + b[0] + b[2:] for a, b in splits if len(b)>1]\n",
    "    replaces   = [a + c + b[1:] for a, b in splits for c in alphabet if b]\n",
    "    inserts    = [a + c + b for a, b in splits for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgPpfeyYgLUv"
   },
   "source": [
    "#Task 3 : Grammaticality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigramProb(word,smoothing,sm):\n",
    "    num = unigramDict.get(word,0)\n",
    "    denum = vocabSize\n",
    "    \n",
    "    if smoothing:\n",
    "        if sm == 1:\n",
    "            num,denum = laplaceSmoothing(num,denum,1)\n",
    "        elif sm == 2:\n",
    "            return goodTuring(unigramDict)\n",
    "        elif sm == 3:\n",
    "            return stupidBackOff(word,sent)\n",
    "    if num == 0 or denum == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(num) / float(denum)\n",
    "\n",
    "def unigramSentCheck(sent):\n",
    "    unigrams = []\n",
    "    temp = []\n",
    "    unigrams,temp = tokenize(sent,unigrams,temp)\n",
    "    sum = 0.0\n",
    "\n",
    "    for uni in unigrams:\n",
    "        pro = unigramProb(uni,True,2)\n",
    "        if pro!=0:\n",
    "            sum += pro\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xX0RvOpLgYgR"
   },
   "outputs": [],
   "source": [
    "# new_nrs = goodTuring(nr_counts)\n",
    "# sorted_newnrs = sorted(new_nrs.items())\n",
    "# print(sorted_newnrs)\n",
    "\n",
    "def bigramProb(prev_word,word,smoothing,sm):\n",
    "    num = bigramDict.get((prev_word,word),0)\n",
    "    denum = unigramDict.get(prev_word,0)\n",
    "    \n",
    "    if smoothing:\n",
    "        if sm == 1:\n",
    "            num,denum = laplaceSmoothing(num,denum,2)\n",
    "        elif sm == 2:\n",
    "            return goodTuring(unigramDict)\n",
    "        elif sm == 3:\n",
    "            return stupidBackOff(word,sent)\n",
    "    if num == 0 or denum == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(num)/float(denum)\n",
    "\n",
    "def bigramSentCheck(sent):\n",
    "    sum = 0.0\n",
    "    previous_word = None\n",
    "    sent = sent.split()\n",
    "    for word in sent:\n",
    "        if previous_word != None:\n",
    "            bigram_prob = bigramProb(previous_word,word,True,2)\n",
    "            if bigram_prob!=0:\n",
    "                sum += bigram_prob\n",
    "        previous_word = word\n",
    "    return sum       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigramProb(prev1_word,prev2_word,word,smoothing,sm):\n",
    "    num = trigramDict.get((prev1_word,prev2_word,word),0)\n",
    "    denum = bigramDict.get((prev1_word,prev2_word),0)\n",
    "    \n",
    "    if smoothing:\n",
    "        if sm == 1:\n",
    "            num,denum = laplaceSmoothing(num,denum,3)\n",
    "        elif sm == 2:\n",
    "            return goodTuring(bigramDict)\n",
    "        elif sm == 3:\n",
    "            return stupidBackOff(word,sent)\n",
    "        \n",
    "    if num == 0 or denum == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(num)/float(denum)\n",
    "    \n",
    "def trigramSentCheck(sent):\n",
    "    sum = 0.0\n",
    "    unique_trigrams = set()\n",
    "    sent = sent.split()\n",
    "    prev1_word = None\n",
    "    prev2_word = None\n",
    "    for word in sent:\n",
    "        if prev1_word != None and prev2_word != None:\n",
    "            trigram_prob = trigramProb(prev1_word,prev2_word,word,True,2)\n",
    "            sum += trigram_prob\n",
    "        \n",
    "        prev1_word = prev2_word\n",
    "        prev2_word = word\n",
    "    return sum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ------------------------------------ MAIN FUNCTION -------------------------------------------------------\n",
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "unigramDict = {}\n",
    "bigramDict = {}\n",
    "trigramDict = {}\n",
    "\n",
    "vocabSize = 0\n",
    "temp_dict = {}\n",
    "\n",
    "startOfSentence = \"<SOS>\"\n",
    "endOfSentence = \"<EOS>\"\n",
    "\n",
    "tokens,sentences = get_tokens()                                                       # Tokenizing\n",
    "language_model(tokens,sentences)                                                      # Building Language Model\n",
    "N = sum(unigramDict.values())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "PlotlyRequestError",
     "evalue": "No message",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 137\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, **response_kw)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_new_proxy_conn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_prepare_proxy\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 146\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7fe048fa25c0>: Failed to establish a new connection: [Errno -2] Name or service not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    375\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                 )\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, **response_kw)\u001b[0m\n\u001b[1;32m    609\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 610\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    611\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='plot.ly', port=443): Max retries exceeded with url: /clientresp (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7fe048fa25c0>: Failed to establish a new connection: [Errno -2] Name or service not known',)))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/plotly/api/v1/utils.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='plot.ly', port=443): Max retries exceeded with url: /clientresp (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7fe048fa25c0>: Failed to establish a new connection: [Errno -2] Name or service not known',)))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPlotlyRequestError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-85ff8a22c939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ------------------------------------ Log plots of frequencies and ngrams ---------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mngramFreqPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munigramDict\u001b[0m\u001b[0;34m)\u001b[0m                                    \u001b[0;31m# Print top 10 and bottom 10 unigrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mngramFreqPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigramDict\u001b[0m\u001b[0;34m)\u001b[0m                                     \u001b[0;31m# Print top 10 and bottom 10 bigrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mngramFreqPlot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigramDict\u001b[0m\u001b[0;34m)\u001b[0m                                    \u001b[0;31m# Print top 10 and bottom 10 trigrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-118bac760a7f>\u001b[0m in \u001b[0;36mngramFreqPlot\u001b[0;34m(ngrams)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mplot_ngram_freqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-c847a43626e1>\u001b[0m in \u001b[0;36mplot_ngram_freqs\u001b[0;34m(word, freq)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'styled-line'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/plotly/plotly/plotly.py\u001b[0m in \u001b[0;36miplot\u001b[0;34m(figure_or_data, **plot_options)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'auto_open'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplot_options\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mplot_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auto_open'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_or_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplot_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_or_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/plotly/plotly/plotly.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(figure_or_data, validate, **plot_options)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mplot_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layout'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclientresp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplot_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;31m# Check if the url needs a secret key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/plotly/api/v1/clientresp.py\u001b[0m in \u001b[0;36mclientresp\u001b[0;34m(data, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{plotly_domain}/clientresp'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Old functionality, just keeping it around.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/plotly/api/v1/utils.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mstatus_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'No content'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlotlyRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mvalidate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPlotlyRequestError\u001b[0m: No message"
     ]
    }
   ],
   "source": [
    "# ------------------------------------ Log plots of frequencies and ngrams ---------------------------------------\n",
    "\n",
    "ngramFreqPlot(unigramDict)                                    # Print top 10 and bottom 10 unigrams\n",
    "ngramFreqPlot(bigramDict)                                     # Print top 10 and bottom 10 bigrams\n",
    "ngramFreqPlot(trigramDict)                                    # Print top 10 and bottom 10 trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions for the misspelled word : \n",
      "{'fairy', 'airy', 'diary', 'daily', 'hairy'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------ Spell Checking and Correction ------------------------------------------------\n",
    "#probabilistic_spellcorrection(\"dairy\")\n",
    "possibilities = spellCheck(\"dairy\",unigramDict)              # SpellChecking\n",
    "\n",
    "print(\"Suggestions for the misspelled word : \")\n",
    "print(possibilities)                                                     # Possible words\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram model\n",
      "1.6619203642245514e-08\n",
      "1.5788243460133238e-08\n",
      "\n",
      "Bigram model\n",
      "1.5788243460133238e-08\n",
      "1.4957283278020963e-08\n",
      "\n",
      "Trigram model\n",
      "2.9460084907113255e-06\n",
      "2.782341352338474e-06\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------ Grammartical Score -------------------------------------------------------\n",
    "\n",
    "correct_stmt = \"<SOS> While the inaugural address was being delivered from this place, devoted altogether to saving the Union without war <EOS>\"\n",
    "wrong_stmt = \"<SOS>  While the inaugural address was being delivered from this place, devoted altogether to saving the Union without war<EOS>\"\n",
    "\n",
    "print(\"Unigram model\")\n",
    "print(unigramSentCheck(correct_stmt))\n",
    "print(unigramSentCheck(wrong_stmt))\n",
    "\n",
    "print(\"\\nBigram model\")\n",
    "print(bigramSentCheck(correct_stmt))\n",
    "print(bigramSentCheck(wrong_stmt))\n",
    "\n",
    "print(\"\\nTrigram model\")\n",
    "print(trigramSentCheck(correct_stmt))\n",
    "print(trigramSentCheck(wrong_stmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------- completeNgram ----------------\n",
      "\n",
      "When ['is', 'there'] was given\n",
      "\n",
      "(('is', 'there', 'any'), 20)\n",
      "(('is', 'there', 'a'), 9)\n",
      "(('is', 'there', 'in'), 9)\n",
      "(('is', 'there', 'anything'), 8)\n",
      "(('is', 'there', 'not'), 5)\n",
      "(('is', 'there', '<EOS>'), 4)\n",
      "(('is', 'there', 'to'), 4)\n",
      "(('is', 'there', 'such'), 4)\n",
      "(('is', 'there', 'then'), 3)\n",
      "(('is', 'there', 'no'), 3)\n",
      "(('is', 'there', 'may'), 3)\n",
      "(('is', 'there', 'has'), 3)\n",
      "(('is', 'there', 'is'), 2)\n",
      "(('is', 'there', 'it'), 2)\n",
      "(('is', 'there', 'they'), 2)\n",
      "(('is', 'there', 'can'), 2)\n",
      "(('is', 'there', 'so'), 1)\n",
      "(('is', 'there', 'for'), 1)\n",
      "(('is', 'there', 'now'), 1)\n",
      "(('is', 'there', 'but'), 1)\n",
      "(('is', 'there', 'nobody'), 1)\n",
      "(('is', 'there', 'something'), 1)\n",
      "(('is', 'there', 'one'), 1)\n",
      "(('is', 'there', 'or'), 1)\n",
      "(('is', 'there', 'room'), 1)\n",
      "(('is', 'there', 'going'), 1)\n",
      "(('is', 'there', 'reason'), 1)\n",
      "(('is', 'there', 'nothing'), 1)\n",
      "(('is', 'there', 'just'), 1)\n",
      "(('is', 'there', 'expressed'), 1)\n",
      "(('is', 'there', 'and'), 1)\n",
      "(('is', 'there', 'we'), 1)\n",
      "(('is', 'there', 'anyone'), 1)\n",
      "(('is', 'there', 'seriously'), 1)\n",
      "(('is', 'there', 'expounded'), 1)\n",
      "(('is', 'there', 'given'), 1)\n"
     ]
    }
   ],
   "source": [
    "#----------------------------- Predict nth word using ngram ------------------\n",
    "completeNgram([\"is\",\"there\"],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Error Correction Demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
